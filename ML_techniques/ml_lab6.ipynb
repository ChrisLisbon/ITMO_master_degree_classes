{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6. Выбор оптимального классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой лабораторной работе вам потребуется выбрать наилучший классификатор с оптимальными параметрами для задачи про пассажиров [\"Титаника\"](https://ru.wikipedia.org/wiki/Титаник)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__  \n",
    "Загрузите данные (см. предыдущую лабораторную работу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "train_data = pd.read_csv('./input/train.csv')\n",
    "test_data = pd.read_csv('./input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__  \n",
    "Проведите предобработку данных (см. предыдущую лабораторную работу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_categories</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age_categories_Adult</th>\n",
       "      <th>Age_categories_Child</th>\n",
       "      <th>Age_categories_Infant</th>\n",
       "      <th>Age_categories_Missing</th>\n",
       "      <th>Age_categories_Senior</th>\n",
       "      <th>Age_categories_Teenager</th>\n",
       "      <th>Age_categories_Young_Adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Young_Adult</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  -0.5      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked Age_categories  Pclass_1  \\\n",
       "0        0         A/5 21171   7.2500   NaN        S    Young_Adult       0.0   \n",
       "1        0          PC 17599  71.2833   C85        C          Adult       1.0   \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S    Young_Adult       0.0   \n",
       "3        0            113803  53.1000  C123        S    Young_Adult       1.0   \n",
       "4        0            373450   8.0500   NaN        S    Young_Adult       0.0   \n",
       "..     ...               ...      ...   ...      ...            ...       ...   \n",
       "886      0            211536  13.0000   NaN        S    Young_Adult       0.0   \n",
       "887      0            112053  30.0000   B42        S    Young_Adult       1.0   \n",
       "888      2        W./C. 6607  23.4500   NaN        S        Missing       0.0   \n",
       "889      0            111369  30.0000  C148        C    Young_Adult       1.0   \n",
       "890      0            370376   7.7500   NaN        Q    Young_Adult       0.0   \n",
       "\n",
       "     Pclass_2  Pclass_3  Sex_female  Sex_male  Age_categories_Adult  \\\n",
       "0         0.0       1.0         0.0       1.0                   0.0   \n",
       "1         0.0       0.0         1.0       0.0                   1.0   \n",
       "2         0.0       1.0         1.0       0.0                   0.0   \n",
       "3         0.0       0.0         1.0       0.0                   0.0   \n",
       "4         0.0       1.0         0.0       1.0                   0.0   \n",
       "..        ...       ...         ...       ...                   ...   \n",
       "886       1.0       0.0         0.0       1.0                   0.0   \n",
       "887       0.0       0.0         1.0       0.0                   0.0   \n",
       "888       0.0       1.0         1.0       0.0                   0.0   \n",
       "889       0.0       0.0         0.0       1.0                   0.0   \n",
       "890       0.0       1.0         0.0       1.0                   0.0   \n",
       "\n",
       "     Age_categories_Child  Age_categories_Infant  Age_categories_Missing  \\\n",
       "0                     0.0                    0.0                     0.0   \n",
       "1                     0.0                    0.0                     0.0   \n",
       "2                     0.0                    0.0                     0.0   \n",
       "3                     0.0                    0.0                     0.0   \n",
       "4                     0.0                    0.0                     0.0   \n",
       "..                    ...                    ...                     ...   \n",
       "886                   0.0                    0.0                     0.0   \n",
       "887                   0.0                    0.0                     0.0   \n",
       "888                   0.0                    0.0                     1.0   \n",
       "889                   0.0                    0.0                     0.0   \n",
       "890                   0.0                    0.0                     0.0   \n",
       "\n",
       "     Age_categories_Senior  Age_categories_Teenager  \\\n",
       "0                      0.0                      0.0   \n",
       "1                      0.0                      0.0   \n",
       "2                      0.0                      0.0   \n",
       "3                      0.0                      0.0   \n",
       "4                      0.0                      0.0   \n",
       "..                     ...                      ...   \n",
       "886                    0.0                      0.0   \n",
       "887                    0.0                      0.0   \n",
       "888                    0.0                      0.0   \n",
       "889                    0.0                      0.0   \n",
       "890                    0.0                      0.0   \n",
       "\n",
       "     Age_categories_Young_Adult  \n",
       "0                           1.0  \n",
       "1                           0.0  \n",
       "2                           1.0  \n",
       "3                           1.0  \n",
       "4                           1.0  \n",
       "..                          ...  \n",
       "886                         1.0  \n",
       "887                         1.0  \n",
       "888                         0.0  \n",
       "889                         1.0  \n",
       "890                         1.0  \n",
       "\n",
       "[891 rows x 25 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_age(df, cut_points, label_names):\n",
    "    df['Age_categories']=df['Age']\n",
    "    for i in range (len(cut_points)-1):\n",
    "        df['Age']=df['Age'].fillna(-0.5)        \n",
    "        df['Age_categories'][(cut_points[i]<df['Age']) & (df['Age']<=cut_points[i+1])]=label_names[i]\n",
    "    return df\n",
    "\n",
    "def create_dummies(df, column_name):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    X=np.array(df[column_name]).reshape(len(df[column_name]), 1)\n",
    "    enc.fit(X)\n",
    "    bin_cod=enc.transform(X).toarray().T\n",
    "    \n",
    "    for i in range (len(np.unique(X))):\n",
    "        name=column_name+'_'+str(np.unique(X)[i])\n",
    "        df[name]=pd.Series(bin_cod[i])    \n",
    "    return df\n",
    "\n",
    "cut_points = [-1, 0, 5, 12, 18, 35, 60, 100]\n",
    "label_names = [\"Missing\", \"Infant\", \"Child\", \"Teenager\", \"Young_Adult\", \"Adult\", \"Senior\"]\n",
    "\n",
    "train = process_age(train_data, cut_points, label_names)\n",
    "test = process_age(test_data,cut_points,label_names)\n",
    "\n",
    "train = create_dummies(train_data, \"Pclass\")\n",
    "test = create_dummies(test_data, \"Pclass\")\n",
    "\n",
    "train = create_dummies(train_data, \"Sex\")\n",
    "test = create_dummies(test_data, \"Sex\")\n",
    "\n",
    "train = create_dummies(train_data, \"Age_categories\")\n",
    "test = create_dummies(test_data, \"Age_categories\")\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3.__  \n",
    "Примените масштабирование признаков (`StandardScaler`, `MinMaxScaler`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "variable=np.array([test['Fare']]).T\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(variable)\n",
    "test['FareScaled']=pd.Series(scaler.transform(variable).T[0])         #test\n",
    "\n",
    "variable=np.array([train['Fare']]).T\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(variable)\n",
    "train['FareScaled']=pd.Series(scaler.transform(variable).T[0])       #train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__  \n",
    "Примените различные преобразования признаков (`PolynomialFeatures`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01415106 0.         0.         ... 1.         0.         0.        ]\n",
      " [0.13913574 1.         0.         ... 0.         1.         0.        ]\n",
      " [0.01546857 0.         0.         ... 1.         0.         0.        ]\n",
      " ...\n",
      " [0.04577135 0.         0.         ... 1.         0.         0.        ]\n",
      " [0.0585561  0.         0.         ... 0.         1.         0.        ]\n",
      " [0.01512699 0.         0.         ... 1.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "variable=train[['FareScaled', 'Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']].to_numpy()\n",
    "print(variable)\n",
    "poly = PolynomialFeatures(3)\n",
    "new_ar=poly.fit_transform(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 5.__  \n",
    "Обучите несколько классификаторов, в том числе:  \n",
    "1. Логистическую регрессию (`LogisticRegression`).\n",
    "1. Метод опорных векторов (`SVC`).\n",
    "1. Метод *k* ближайших соседей (`KNeighborsClassifier`).\n",
    "1. Наивный байесовский классификатор (`MultinomialNB`).\n",
    "1. Деревья решений (`DecisionTreeClassifier`).\n",
    "1. Случайный лес (`RandomForestClassifier`).\n",
    "1. AdaBoost (`AdaBoost`).\n",
    "1. Градиентный бустинг (`GradientBoostingClassifier`).\n",
    "\n",
    "Для обучения и проверки качества можно использовать функцию `train_test_split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "(712, 560)\n",
      "\n",
      "X_test:\n",
      "(179, 560)\n",
      "\n",
      "y_train:\n",
      "(712,)\n",
      "\n",
      "y_test:\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "# разбиение выборки\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=new_ar\n",
    "y=np.array(train['Survived'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('X_train:')\n",
    "print(X_train.shape)\n",
    "print('\\nX_test:')\n",
    "print(X_test.shape)\n",
    "print('\\ny_train:')\n",
    "print(y_train.shape)\n",
    "print('\\ny_test:')\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LogisticRegression()\n",
      "Accuracy (test):\n",
      "0.8212290502793296\n",
      "\n",
      "\n",
      "SVC(gamma='auto')\n",
      "Accuracy (test):\n",
      "0.7821229050279329\n",
      "\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Accuracy (test):\n",
      "0.8379888268156425\n",
      "\n",
      "\n",
      "MultinomialNB()\n",
      "Accuracy (test):\n",
      "0.8044692737430168\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "Accuracy (test):\n",
      "0.8324022346368715\n",
      "\n",
      "\n",
      "RandomForestClassifier(max_depth=5, random_state=0)\n",
      "Accuracy (test):\n",
      "0.8156424581005587\n",
      "\n",
      "\n",
      "AdaBoostClassifier(n_estimators=100, random_state=0)\n",
      "Accuracy (test):\n",
      "0.8044692737430168\n",
      "\n",
      "\n",
      "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)\n",
      "Accuracy (test):\n",
      "0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "clfs=[LogisticRegression(), SVC(gamma='auto'), KNeighborsClassifier(n_neighbors=5), MultinomialNB(), \n",
    "      DecisionTreeClassifier(random_state=0), RandomForestClassifier(max_depth=5, random_state=0),\n",
    "      AdaBoostClassifier(n_estimators=100, random_state=0), \n",
    "      GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)]\n",
    "for classif in clfs:\n",
    "    clf=classif\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('\\n')\n",
    "    print(classif)\n",
    "    print('Accuracy (test):')\n",
    "    print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# без фич и масштаб-я\n",
    "X=train[['FareScaled', 'Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']]\n",
    "y=np.array(train['Survived'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LogisticRegression()\n",
      "Accuracy (test):\n",
      "0.8044692737430168\n",
      "\n",
      "\n",
      "SVC(gamma='auto')\n",
      "Accuracy (test):\n",
      "0.7877094972067039\n",
      "\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Accuracy (test):\n",
      "0.8379888268156425\n",
      "\n",
      "\n",
      "MultinomialNB()\n",
      "Accuracy (test):\n",
      "0.770949720670391\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "Accuracy (test):\n",
      "0.8156424581005587\n",
      "\n",
      "\n",
      "RandomForestClassifier(max_depth=5, random_state=0)\n",
      "Accuracy (test):\n",
      "0.8100558659217877\n",
      "\n",
      "\n",
      "AdaBoostClassifier(n_estimators=100, random_state=0)\n",
      "Accuracy (test):\n",
      "0.7932960893854749\n",
      "\n",
      "\n",
      "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)\n",
      "Accuracy (test):\n",
      "0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "clfs=[LogisticRegression(), SVC(gamma='auto'), KNeighborsClassifier(n_neighbors=5), MultinomialNB(), \n",
    "      DecisionTreeClassifier(random_state=0), RandomForestClassifier(max_depth=5, random_state=0),\n",
    "      AdaBoostClassifier(n_estimators=100, random_state=0), \n",
    "      GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)]\n",
    "for classif in clfs:\n",
    "    clf=classif\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('\\n')\n",
    "    print(classif)\n",
    "    print('Accuracy (test):')\n",
    "    print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6.__  \n",
    "При помощи `Pipeline` и `GridSearchCV` выберите оптимальную архитектуру:\n",
    "1. Метод масштабирования.\n",
    "1. Степень полинома в `PolynomialFeatures`.\n",
    "1. Параметры классификаторов (в том числе, параметры регуляризации).\n",
    "\n",
    "Заносите в таблицу Excel результаты тестирования (варианты параметров, оценки качества)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train[['FareScaled', 'Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2', 'Fare']]\n",
    "y=np.array(train['Survived'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "{'linear_model__C': 1.0, 'preprocessing__degree': 1}\n",
      "0.7879084967320261\n",
      "\n",
      "MinMaxScaler\n",
      "{'linear_model__C': 1.5, 'preprocessing__degree': 1}\n",
      "0.8101307189542485\n"
     ]
    }
   ],
   "source": [
    "# Логистическая регрессия\n",
    "\n",
    "parameters_grid = {\n",
    "       'linear_model__C' : np.arange(1, 2, 0.5), # параметр регуляризации\n",
    "       'preprocessing__degree': np.arange(1, 3),\n",
    "   }\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()), ('preprocessing', PolynomialFeatures()), ('linear_model', LogisticRegression())])\n",
    "#print(classifier.get_params())\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nStandardScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('linear_model', LogisticRegression())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "{'neighbors__n_neighbors': 6, 'preprocessing__degree': 1}\n",
      "0.7882352941176469\n",
      "\n",
      "MinMaxScaler\n",
      "{'neighbors__n_neighbors': 10, 'preprocessing__degree': 1}\n",
      "0.7879084967320261\n"
     ]
    }
   ],
   "source": [
    "# K-MEANS\n",
    "\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "parameters_grid = {\n",
    "       'neighbors__n_neighbors' : np.arange(1, 20),\n",
    "       'preprocessing__degree': np.arange(1, 3),\n",
    "   }\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()), ('preprocessing', PolynomialFeatures()), ('neighbors', KNeighborsClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nStandardScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('neighbors', KNeighborsClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "{'preprocessing__degree': 1, 'svm__C': 1.0, 'svm__degree': 1, 'svm__gamma': 'auto', 'svm__kernel': 'linear'}\n",
      "0.8101307189542484\n",
      "\n",
      "MinMaxScaler\n",
      "{'preprocessing__degree': 1, 'svm__C': 1.2, 'svm__degree': 1, 'svm__gamma': 'auto', 'svm__kernel': 'linear'}\n",
      "0.8156862745098039\n"
     ]
    }
   ],
   "source": [
    "# Метод опорных векторов\n",
    "\n",
    "parameters_grid = {\n",
    "       'svm__C' : np.arange(1, 2, 0.2), # параметр регуляризации\n",
    "       'svm__gamma' : [ 'auto'],#'scale',\n",
    "       'svm__kernel' : [ 'poly', 'linear', 'sigmoid','rbf'],\n",
    "       'svm__degree': np.arange(1, 5),      \n",
    "       'preprocessing__degree': np.arange(1, 3),\n",
    "   }\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()), ('preprocessing', PolynomialFeatures()), ('svm', SVC())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nStandardScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('svm', SVC())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MinMaxScaler\n",
      "{'naive_bayes__alpha': 1.0, 'preprocessing__degree': 2}\n",
      "0.7549019607843137\n"
     ]
    }
   ],
   "source": [
    "# Наивный байесовский классификатор\n",
    "\n",
    "parameters_grid = {\n",
    "       'naive_bayes__alpha' : np.arange(1, 3, 0.2),        \n",
    "       'preprocessing__degree': np.arange(1, 3),\n",
    "   }\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('naive_bayes', MultinomialNB())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "{'preprocessing__degree': 2}\n",
      "0.7437908496732026\n",
      "\n",
      "MinMaxScaler\n",
      "{'preprocessing__degree': 2}\n",
      "0.7326797385620913\n"
     ]
    }
   ],
   "source": [
    "# Деревья решений\n",
    "\n",
    "parameters_grid = {           \n",
    "       'preprocessing__degree': np.arange(1,3),\n",
    "       'decisions__criterion' : ['gini', 'entropy'], \n",
    "        'decisions__splitter': ['best', 'random'],\n",
    "        'decisions__min_samples_split' : np.arange(1, 5, 1),\n",
    "        'decisions__min_samples_leaf' : np.arange(1, 5, 1),\n",
    "        'decisions__max_features' : ['auto', 'sqrt','log2'],# \n",
    "        'decisions__min_impurity_decrease': np.arange(0, 1, 0.2), \n",
    "   }\n",
    "\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()), ('preprocessing', PolynomialFeatures()), ('decisions', DecisionTreeClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nStandardScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('decisions', DecisionTreeClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "{'ensemble__max_depth': 2, 'preprocessing__degree': 2}\n",
      "0.7771241830065359\n",
      "\n",
      "MinMaxScaler\n",
      "{'ensemble__max_depth': 5, 'preprocessing__degree': 2}\n",
      "0.7771241830065359\n"
     ]
    }
   ],
   "source": [
    "# Случайный лес\n",
    "\n",
    "parameters_grid = {\n",
    "       'ensemble__max_depth': np.arange(1, 7),       \n",
    "       'preprocessing__degree': np.arange(1, 3), \n",
    "   }\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()), ('preprocessing', PolynomialFeatures()), ('ensemble', RandomForestClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nStandardScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('ensemble', RandomForestClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "{'ensemble__n_estimators': 100, 'preprocessing__degree': 1}\n",
      "0.7601307189542483\n",
      "\n",
      "MinMaxScaler\n",
      "{'ensemble__n_estimators': 100, 'preprocessing__degree': 1}\n",
      "0.7601307189542483\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost \n",
    "\n",
    "parameters_grid = {    \n",
    "       'preprocessing__degree': np.arange(1, 4),\n",
    "       'ensemble__n_estimators' : np.arange(95, 105),\n",
    "   }\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()), ('preprocessing', PolynomialFeatures()), ('ensemble', AdaBoostClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nStandardScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('ensemble', AdaBoostClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "{'ensemble__learning_rate': 0.9, 'ensemble__max_depth': 2, 'ensemble__n_estimators': 103, 'preprocessing__degree': 1}\n",
      "0.7937908496732027\n",
      "\n",
      "MinMaxScaler\n",
      "{'ensemble__learning_rate': 0.9, 'ensemble__max_depth': 2, 'ensemble__n_estimators': 95, 'preprocessing__degree': 1}\n",
      "0.7937908496732027\n"
     ]
    }
   ],
   "source": [
    "# Градиентный бустинг\n",
    "\n",
    "parameters_grid = {    \n",
    "       'preprocessing__degree': np.arange(1, 3),\n",
    "       'ensemble__n_estimators' : np.arange(95, 105),\n",
    "       'ensemble__learning_rate' : np.arange(0, 1, 0.1),\n",
    "       'ensemble__max_depth' : np.arange(1, 10),\n",
    "   }\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()), ('preprocessing', PolynomialFeatures()), ('ensemble', GradientBoostingClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nStandardScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)\n",
    "\n",
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures()), ('ensemble', GradientBoostingClassifier())])\n",
    "cv = StratifiedKFold(n_splits=10, random_state=0)\n",
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(X_test, y_test)\n",
    "print('\\nMinMaxScaler')\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 7.__  \n",
    "1. Выберите несколько лучших классификаторов (от 3 до 10).\n",
    "1. Обучите выбранные классификаторы на всех доступных размеченных данных.\n",
    "1. Получите результаты предсказания для тестовых данных.\n",
    "1. Отправьте результаты на сервер [Kaggle](https://ru.wikipedia.org/wiki/Титаник)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(train[['Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']])\n",
    "y=np.array(train['Survived'])\n",
    "X_test=np.array(test[['Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']])\n",
    "\n",
    "      \n",
    "poly = PolynomialFeatures(3)\n",
    "X=poly.fit_transform(X)\n",
    "X_test=poly.fit_transform(X_test)\n",
    "\n",
    "clf=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf.fit(X, y)\n",
    "predictions=clf.predict(X_test)\n",
    "\n",
    "test_ids = test[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": test_ids,\n",
    "                 \"Survived\": predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv('output/GradientBoostingClassifier(3d).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(train[['Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']])\n",
    "y=np.array(train['Survived'])\n",
    "X_test=np.array(test[['Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']])\n",
    "\n",
    "      \n",
    "poly = PolynomialFeatures(3)\n",
    "X=poly.fit_transform(X)\n",
    "X_test=poly.fit_transform(X_test)\n",
    "\n",
    "clf=AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X, y)\n",
    "predictions=clf.predict(X_test)\n",
    "\n",
    "test_ids = test[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": test_ids,\n",
    "                 \"Survived\": predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv('output/AdaBoostClassifier(3d).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(train[['Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']])\n",
    "y=np.array(train['Survived'])\n",
    "X_test=np.array(test[['Age_categories_Adult', 'Age_categories_Child', 'Age_categories_Infant', 'Age_categories_Missing', 'Age_categories_Senior', 'Age_categories_Teenager', 'Age_categories_Young_Adult',\n",
    "                  'Sex_female', 'Sex_male', 'Pclass_3', 'Pclass_1', 'Pclass_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([('scaler', MinMaxScaler()), ('preprocessing', PolynomialFeatures(2)), \n",
    "                       ('decisions', DecisionTreeClassifier(criterion='entropy', max_features='sqrt', min_impurity_decrease=0,\n",
    "                                                           min_samples_leaf = 3, min_samples_split = 3, splitter = 'random'))])\n",
    "classifier.fit(X, y)\n",
    "predictions=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": test_ids,\n",
    "                 \"Survived\": predictions}\n",
    "submission = pd.DataFrame(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/DecisionTreeClassifier_titanic_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X, y)\n",
    "predictions=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": test_ids,\n",
    "                 \"Survived\": predictions}\n",
    "submission = pd.DataFrame(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/KNeighborsClassifier_titanic_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=30)\n",
    "clf.fit(X, y)\n",
    "predictions=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": test_ids,\n",
    "                 \"Survived\": predictions}\n",
    "submission = pd.DataFrame(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/RandomForestClassifier_titanic_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
